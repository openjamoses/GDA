{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from numpy.random import choice\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#sns.set_style('darkgrid')\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our path to all the dataset genrated or loaded will be specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/Users/mosesopenja/Documents/Fall2020/Machine-learning/assignment2/dataset/hwk2_datasets/'\n",
    "#path_output = '/Users/mosesopenja/Documents/Fall2020/Machine-learning/assignment2/dataset/generated/'\n",
    "\n",
    "path = './inputs/'\n",
    "path_output = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification and Nearest Neighbor Classification\n",
    "\n",
    "\n",
    "\n",
    "### Question 1.\n",
    "\n",
    "1. You will use a synthetic data set for the classification task that youâ€™ll generate yourself.\n",
    "Generate two classes with 20 features each. Each class is given by a multivariate Gaussian\n",
    "distribution, with both classes sharing the same covariance matrix. You are provided\n",
    "with the mean vectors (DS1-m0 for mean vector of negative class and DS1-m1 for mean\n",
    "vector of positive class) and the covariance matrix (DS1-cov). Generate 2000 examples\n",
    "for each class, and label the data to be positive if they came from the Gaussian with\n",
    "mean m1 and negative if they came from the Gaussian with mean m0. Randomly pick\n",
    "(without replacement) 20% of each class (i.e., 400 data points per class) as test set, 20%\n",
    "of each class (i.e., 400 data points per class) as validation set set and train the classifiers\n",
    "on the remaining 60% data. When you report performance results, it should be on the\n",
    "test set.  Call this dataset as DS1, and submit it with your code. Follow the instructions\n",
    "from Assignment 1 for data submission format.\n",
    "\n",
    "#### Lets start by loading the neccasary dataset DS1_m_0.txt, DS1_m_1.txt, and DS1_Cov.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS1_m_0 = np.genfromtxt(path+'DS1_m_0.txt', delimiter=',')[:-1]# load the mean0 and remove the last emply string\n",
    "DS1_m_1 = np.genfromtxt(path+'DS1_m_1.txt', delimiter=',')[:-1]# load the mean1 and remove the last emply string\n",
    "DS1_Cov = np.genfromtxt(path+'DS1_Cov.txt', delimiter=',')[:,:-1] # load the covariace and remove the last emply string\n",
    "DS1_m_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_target_value(class_array, target_array):\n",
    "    return np.append(class_array,target_array.reshape(-1,1), axis=1)\n",
    "def append_more_rows(class_array_1, class_array_2):\n",
    "    return np.append(class_array_1,class_array_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = np.random.multivariate_normal(DS1_m_0, DS1_Cov, 2000)\n",
    "pos = np.random.multivariate_normal(DS1_m_1, DS1_Cov, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_negative = append_target_value(neg, np.zeros((2000,1), dtype=int)) # append the targets 0 for negative class\n",
    "class_positive = append_target_value(pos, np.ones((2000,1), dtype=int)) # append the targets 1 for positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function to split the data into train, test validate as 600,200,200\n",
    "def train_test_valid_split(class_data):\n",
    "    train, test = train_test_split(class_data, test_size=0.2, random_state=42)\n",
    "    train, valid = train_test_split(train, test_size=0.25, random_state=42)\n",
    "    return train, test, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the function defined in upper scope to split our data\n",
    "train_1, test_1, valid_1 = train_test_valid_split(class_negative)\n",
    "train_2, test_2, valid_2 = train_test_valid_split(class_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets join the dataset of class 1 and two\n",
    "train = np.append(train_1, train_2, axis=0)\n",
    "test = np.append(test_1, test_2, axis=0)\n",
    "valid = np.append(valid_1, valid_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 21) (800, 21) (800, 21)\n"
     ]
    }
   ],
   "source": [
    "# lets check the shape of our final dataset:\n",
    "print(train.shape,test.shape, valid.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump the dataset as csv files with the format defined in the TP intructions:\n",
    "np.savetxt(path_output+\"DS1_train.csv\", train, delimiter=\",\")\n",
    "np.savetxt(path_output+\"DS1_test.csv\", test, delimiter=\",\")\n",
    "np.savetxt(path_output+\"DS1_valid.csv\", valid, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets implement K-NN clafication algorithm  that I can use to test the performance of the dataset generated\n",
    "\n",
    "The algorithm expect the two params x_train and y_train to fit the dataset and test set to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind the function for euclidean distance given two vectors\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "class KNN(): # Class KNearestNeighbours goes here..!\n",
    "    def __init__(self, K=5): # we can set the default neightbours to 5\n",
    "        self.K = K\n",
    "    def fit(self, x_train, y_train): # fit function expect the vectors and the target\n",
    "        self.X_train = x_train\n",
    "        self.Y_train = y_train\n",
    "    def predict(self, X_test): \n",
    "        # list to store all our predictions\n",
    "        predictions = []\n",
    "        # loop over all observations in the test set\n",
    "        for i in range(len(X_test)):            \n",
    "            # find the value of distance between the test point and all other points in the training set\n",
    "            dist = np.array([euclidean_distance(X_test[i], x_t) for x_t in self.X_train])\n",
    "            # we can now sort the distances and return the indices of K neighbors\n",
    "            dist_sorted = dist.argsort()[:self.K]\n",
    "            # pick the neighbors\n",
    "            neighbors_count = {}\n",
    "            # for each neighbor find the class\n",
    "            for idx in dist_sorted:\n",
    "                if self.Y_train[idx][0] in neighbors_count:\n",
    "                    neighbors_count[self.Y_train[idx][0]] += 1\n",
    "                else:\n",
    "                    neighbors_count[self.Y_train[idx][0]] = 1\n",
    "            # sort the neighbours_count\n",
    "            sorted_neighbors_count = sorted(neighbors_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "            # lets add/ append our class label to the predict list\n",
    "            predictions.append(sorted_neighbors_count[0][0])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets extract the target from the train and test\n",
    "x_train = train[0:,0:20]\n",
    "y_train = train[0:,20:]\n",
    "x_test = test[0:,0:20]\n",
    "y_test = test[0:,20:]\n",
    "x_valid = test[0:,0:20]\n",
    "y_valid = test[0:,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''testing the performance of our dataset with KNN classifier defined in the upper scope\n",
    "   --- we can use K=5, for now -----'''\n",
    "knn_model = KNN(K=5)\n",
    "knn_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_metrics(gda_pred):\n",
    "    accuracy = metrics.accuracy_score(y_test, gda_pred)          # accuracy: (tp + tn) / (p + n)\n",
    "    precision = metrics.precision_score(y_test, gda_pred)        # precision tp / (tp + fp)\n",
    "    recall = metrics.recall_score(y_test, gda_pred)              # recall: tp / (tp + fn)\n",
    "    f1 = metrics.f1_score(y_test, gda_pred)                      # f1: 2 tp / (2 tp + fp + fn)\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the performance of our dataset!\n",
    "pred = knn_model.predict(x_test)# NOTE: predict step in KNN is much slower than the train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, accuracy = get_scores_metrics(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.578750\n",
      "Precision: 0.583113\n",
      "Recall: 0.552500\n",
      "F1 score: 0.567394\n"
     ]
    }
   ],
   "source": [
    "#print the results\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.\n",
    "\n",
    "2. We first consider the GDA model as seen in class: given the class variable, the data are assumed to be Gaussians with different means for different classes but with the same covariance matrix. This model can formally be specified as follows:\n",
    "\n",
    " 1. Estimate the parameters of the GDA model using the maximum likelihood approach.\n",
    " \n",
    " a). For DS1, report the best fit accuracy, precision, recall and F-measure achieved\n",
    "by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets implement a GDA classifier\n",
    "\n",
    "class GDAClassification:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.labels, self.class_priors = np.unique(y, return_counts=True)\n",
    "        self.class_priors = self.class_priors / y.shape[0]\n",
    "        \n",
    "        self.Train_Data = X\n",
    "        self.Train_Label = y\n",
    "        \n",
    "        print(self.labels)\n",
    "        \n",
    "        self.dict_data = {}\n",
    "        self.dict_data_count = {}\n",
    "        for (data,label) in zip(self.Train_Data,self.Train_Label):\n",
    " \n",
    "            if label[0] in self.dict_data.keys():\n",
    "                temp = self.dict_data.get(label[0])\n",
    "                temp_count = self.dict_data_count.get(label[0])\n",
    "                temp_count += 1\n",
    "                temp.append(list(data))\n",
    "                self.dict_data[label[0]] = temp\n",
    "                self.dict_data_count[label[0]] = temp_count\n",
    "            else:\n",
    "                self.dict_data[label[0]] = [list(data)]\n",
    "                self.dict_data_count[label[0]] = 1\n",
    "            \n",
    "                    \n",
    "        # Binomial probability goas here:\n",
    "        row,col = np.shape(X)\n",
    "        self.binomial_dict = {}\n",
    "        for key, val in self.dict_data_count.items():\n",
    "            self.binomial_dict[key] = val*1.0/row\n",
    "        \n",
    "        dict_data_array = {}\n",
    "        data_sum_dict = {}\n",
    "        for k, v in self.dict_data.items():\n",
    "            dict_data_array[k] = np.array(v)\n",
    "            data_sum_dict[k]= np.sum(np.array(v),0)\n",
    "        \n",
    "        self.mu_data = {}\n",
    "        for k, v in data_sum_dict.items():\n",
    "            self.mu_data[k] = v*1.0/self.dict_data_count[k]\n",
    "            \n",
    "        dict_data_array2 = {}    \n",
    "        for k, v in dict_data_array.items():\n",
    "            dict_data_array2[k] = v-self.mu_data[k]\n",
    "        \n",
    "        self.sigma = []\n",
    "        \n",
    "        for k,v in dict_data_array2.items():\n",
    "            for deta in v:\n",
    "                deta = deta.reshape(1,col)\n",
    "                ans = deta.T.dot(deta)\n",
    "                self.sigma.append(ans)\n",
    "\n",
    "        self.sigma = np.array(self.sigma)\n",
    "        #print(np.shape(self.sigma))\n",
    "        self.sigma = np.sum(self.sigma,0)\n",
    "        self.sigma = self.sigma/row\n",
    "        \n",
    "        \n",
    "        for k, v in self.mu_data.items():\n",
    "            self.mu_data[k] = v.reshape(1,col)\n",
    "            print(\"Mu_{}: {}\".format(k,v.reshape(1,col)))\n",
    "        print(self.sigma)\n",
    "        \n",
    "    def gaussian(self, x, mean, cov):\n",
    "        \n",
    "        dim = np.shape(cov)[0]\n",
    "        # Cov measures of the determinant is zero\n",
    "        covdet = np.linalg.det(cov + np.eye(dim) * 0.001)\n",
    "        covinv = np.linalg.inv(cov + np.eye(dim) * 0.001)\n",
    "        xdiff = (x - mean).reshape((1, dim))\n",
    "        # Probability Density\n",
    "        p_density = 1.0 / (np.power(np.power(2 * np.pi, dim) * np.abs(covdet), 0.5)) * \\\n",
    "               np.exp(-0.5 * xdiff.dot(covinv).dot(xdiff.T))[0][0]\n",
    "        return p_density\n",
    "\n",
    "    def predict(self,test_data):\n",
    "        predict_label = []\n",
    "        for data in test_data:\n",
    "            max_label = 0\n",
    "            max_likehood = 0\n",
    "            for lab in self.labels:\n",
    "                likelihood = self.gaussian(data,self.mu_data[lab],self.sigma)\n",
    "                if likelihood >= max_likehood:\n",
    "                    max_likehood = likelihood\n",
    "                    max_label = lab\n",
    "            predict_label.append(max_label)\n",
    "        return predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "Mu_0.0: [[1.35464974 1.31507699 1.3314178  1.2815658  1.32796116 1.3255876\n",
      "  1.2801238  1.30097595 1.29455227 1.19711815 1.33164364 1.30814516\n",
      "  1.24153705 1.30350525 1.36083324 1.34496766 1.37031654 1.3047932\n",
      "  1.34410696 1.29102756]]\n",
      "Mu_1.0: [[2.11957295 2.09784241 2.0733269  2.08536989 2.07177151 2.09712021\n",
      "  2.08439585 2.12640347 2.12214562 2.16672049 2.05441559 2.12151196\n",
      "  2.13261964 2.13715674 2.07409241 2.12984784 2.0945371  2.12444338\n",
      "  2.08053467 2.06898178]]\n",
      "[[8.05737947 5.49391003 6.13895501 5.28240859 5.93593272 6.08110628\n",
      "  4.5398847  5.3466409  5.05495747 5.19376925 4.07712252 5.21028971\n",
      "  7.15659755 6.18175617 6.15940356 5.90644234 5.91970428 5.8573333\n",
      "  5.63549282 6.12416714]\n",
      " [5.49391003 6.91870004 5.35184565 4.3595837  5.48277723 5.5054034\n",
      "  4.21500962 3.77226978 4.20085728 5.00453663 3.42320773 4.54801931\n",
      "  5.84677566 5.19180032 5.44611408 5.10122074 5.72850822 5.2261086\n",
      "  5.3282477  5.39502424]\n",
      " [6.13895501 5.35184565 7.18241428 4.82499666 5.77823116 6.46099137\n",
      "  4.45306066 4.60760548 4.93660254 5.11242563 3.35785694 4.62818144\n",
      "  6.37865983 5.27008965 6.04680943 5.73292495 6.26631933 5.08748128\n",
      "  4.70722455 5.12044042]\n",
      " [5.28240859 4.3595837  4.82499666 5.88242626 5.30383957 4.461602\n",
      "  3.57793361 4.30383839 3.43362628 4.23488128 2.8203525  4.12812254\n",
      "  5.93396329 4.94200038 4.83490021 4.96317652 4.72388777 4.67545374\n",
      "  3.91642047 5.96233882]\n",
      " [5.93593272 5.48277723 5.77823116 5.30383957 7.0886827  5.36294003\n",
      "  4.92463012 4.27716685 4.77164452 5.24350366 4.20901502 4.98224377\n",
      "  6.3232926  6.03716835 6.01280267 6.06757317 5.97096581 5.28474034\n",
      "  5.40850467 5.91868803]\n",
      " [6.08110628 5.5054034  6.46099137 4.461602   5.36294003 6.57750654\n",
      "  4.30151672 4.66538337 4.79187718 5.31097601 3.03873813 4.7338649\n",
      "  6.33058344 5.06333717 5.75932387 5.77705226 5.92747801 5.03654416\n",
      "  4.75852173 5.25722275]\n",
      " [4.5398847  4.21500962 4.45306066 3.57793361 4.92463012 4.30151672\n",
      "  5.03558306 3.68983427 3.9020276  4.25553749 2.96560423 4.21682281\n",
      "  4.55825914 4.09273645 4.61336724 5.07941955 4.21008627 3.61537371\n",
      "  4.5244291  3.83194862]\n",
      " [5.3466409  3.77226978 4.60760548 4.30383839 4.27716685 4.66538337\n",
      "  3.68983427 5.65289803 3.54406513 4.74092424 2.53158475 4.66190972\n",
      "  6.01767094 5.08629534 4.76285169 5.85174304 4.37919351 4.81844458\n",
      "  4.64801772 4.53638487]\n",
      " [5.05495747 4.20085728 4.93660254 3.43362628 4.77164452 4.79187718\n",
      "  3.9020276  3.54406513 5.06729274 4.81414459 3.24946677 4.12336568\n",
      "  5.2509846  4.81614854 4.97747011 5.12139089 5.22826855 4.23138389\n",
      "  4.29647408 4.26128034]\n",
      " [5.19376925 5.00453663 5.11242563 4.23488128 5.24350366 5.31097601\n",
      "  4.25553749 4.74092424 4.81414459 7.18369493 3.37420655 4.69199072\n",
      "  6.95290706 5.31131296 5.10562018 5.96685632 4.84949236 5.36332448\n",
      "  4.52483546 5.59108248]\n",
      " [4.07712252 3.42320773 3.35785694 2.8203525  4.20901502 3.03873813\n",
      "  2.96560423 2.53158475 3.24946677 3.37420655 3.45379477 2.93765425\n",
      "  3.85914887 4.0895901  3.71460533 3.68324955 3.75772989 3.35409969\n",
      "  3.80784289 3.63032008]\n",
      " [5.21028971 4.54801931 4.62818144 4.12812254 4.98224377 4.7338649\n",
      "  4.21682281 4.66190972 4.12336568 4.69199072 2.93765425 5.16043398\n",
      "  5.96416242 5.05591479 4.79231648 5.38922305 5.03792235 4.87181457\n",
      "  4.97009802 4.57134916]\n",
      " [7.15659755 5.84677566 6.37865983 5.93396329 6.3232926  6.33058344\n",
      "  4.55825914 6.01767094 5.2509846  6.95290706 3.85914887 5.96416242\n",
      "  9.24084335 6.47244163 6.31705614 6.50536548 6.08295086 6.50324938\n",
      "  5.86992508 7.55395988]\n",
      " [6.18175617 5.19180032 5.27008965 4.94200038 6.03716835 5.06333717\n",
      "  4.09273645 5.08629534 4.81614854 5.31131296 4.0895901  5.05591479\n",
      "  6.47244163 7.10042494 5.97667362 6.17704169 5.87442585 5.77085946\n",
      "  5.93338694 5.77215622]\n",
      " [6.15940356 5.44611408 6.04680943 4.83490021 6.01280267 5.75932387\n",
      "  4.61336724 4.76285169 4.97747011 5.10562018 3.71460533 4.79231648\n",
      "  6.31705614 5.97667362 6.93925076 7.00892454 5.86169091 5.26216103\n",
      "  5.4749091  5.87849216]\n",
      " [5.90644234 5.10122074 5.73292495 4.96317652 6.06757317 5.77705226\n",
      "  5.07941955 5.85174304 5.12139089 5.96685632 3.68324955 5.38922305\n",
      "  6.50536548 6.17704169 7.00892454 8.99987219 5.69993703 5.87001774\n",
      "  5.54894863 5.9899523 ]\n",
      " [5.91970428 5.72850822 6.26631933 4.72388777 5.97096581 5.92747801\n",
      "  4.21008627 4.37919351 5.22826855 4.84949236 3.75772989 5.03792235\n",
      "  6.08295086 5.87442585 5.86169091 5.69993703 6.89681179 5.3497373\n",
      "  5.36961559 5.09681343]\n",
      " [5.8573333  5.2261086  5.08748128 4.67545374 5.28474034 5.03654416\n",
      "  3.61537371 4.81844458 4.23138389 5.36332448 3.35409969 4.87181457\n",
      "  6.50324938 5.77085946 5.26216103 5.87001774 5.3497373  6.12940812\n",
      "  4.8960283  5.39884394]\n",
      " [5.63549282 5.3282477  4.70722455 3.91642047 5.40850467 4.75852173\n",
      "  4.5244291  4.64801772 4.29647408 4.52483546 3.80784289 4.97009802\n",
      "  5.86992508 5.93338694 5.4749091  5.54894863 5.36961559 4.8960283\n",
      "  6.31908458 5.00974647]\n",
      " [6.12416714 5.39502424 5.12044042 5.96233882 5.91868803 5.25722275\n",
      "  3.83194862 4.53638487 4.26128034 5.59108248 3.63032008 4.57134916\n",
      "  7.55395988 5.77215622 5.87849216 5.9899523  5.09681343 5.39884394\n",
      "  5.00974647 8.31314856]]\n"
     ]
    }
   ],
   "source": [
    "# train and test the performance of our Dataset DS1 with GDA above\n",
    "gda = GDAClassification()\n",
    "gda.fit(x_train,y_train)\n",
    "gda_pred = gda.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_metrics(gda_pred):\n",
    "    accuracy = metrics.accuracy_score(y_test, gda_pred)          # accuracy: (tp + tn) / (p + n)\n",
    "    precision = metrics.precision_score(y_test, gda_pred, average='macro')        # precision tp / (tp + fp)\n",
    "    recall = metrics.recall_score(y_test, gda_pred, average='macro')              # recall: tp / (tp + fn)\n",
    "    f1 = metrics.f1_score(y_test, gda_pred, average='macro')                      # f1: 2 tp / (2 tp + fp + fn)\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, accuracy = get_scores_metrics(gda_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966250\n",
      "Precision: 0.966276\n",
      "Recall: 0.966250\n",
      "F1 score: 0.966250\n"
     ]
    }
   ],
   "source": [
    "#print the results\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "3. For DS1, use k-NN to learn a classifier. Repeat the experiment for different values of k\n",
    "and report the performance for each value. We will compare this non-linear classifier to\n",
    "the linear approach, and find out how powerful linear classifiers can be.\n",
    "\n",
    "\n",
    "(a) Does this classifier performs better than GDA or worse? Are there particular values\n",
    "of k which perform better? Why does this happen ? Use F1-Measure for model\n",
    "selection.\n",
    "\n",
    "(b) Report the best fit accuracy, precision, recall and f-measure achieved by this clas-\n",
    "sifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind the function for euclidean distance given two vectors\n",
    "def e_distance(x1, x2): \n",
    "        return np.sqrt(np.sum((x1-x2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(): # Class KNearestNeighbours goes here..!\n",
    "    def __init__(self, K=5): # we can set the default neightbours to 5\n",
    "        self.K = K\n",
    "    def fit(self, x_train, y_train): # fit function expect the vectors and the target\n",
    "        self.X_train = x_train\n",
    "        self.Y_train = y_train\n",
    "    def predict(self, X_test): \n",
    "        # list to store all our predictions\n",
    "        predictions = []\n",
    "        # loop over all observations in the test set\n",
    "        for i in range(len(X_test)):            \n",
    "            # find the value of distance between the test point and all other points in the training set\n",
    "            dist = np.array([e_distance(X_test[i], x_t) for x_t in self.X_train])\n",
    "            # we can now sort the distances and return the indices of K neighbors\n",
    "            dist_sorted = dist.argsort()[:self.K]\n",
    "            # pick the neighbors\n",
    "            neighbors_count = {}\n",
    "            # for each neighbor find the class\n",
    "            for idx in dist_sorted:\n",
    "                if self.Y_train[idx][0] in neighbors_count:\n",
    "                    neighbors_count[self.Y_train[idx][0]] += 1\n",
    "                else:\n",
    "                    neighbors_count[self.Y_train[idx][0]] = 1\n",
    "            # sort the neighbours_count\n",
    "            sorted_neighbors_count = sorted(neighbors_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "            # lets add/ append our class label to the predict list\n",
    "            predictions.append(sorted_neighbors_count[0][0])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_metrics(gda_pred, y):\n",
    "    accuracy = metrics.accuracy_score(y, gda_pred)          # accuracy: (tp + tn) / (p + n)\n",
    "    precision = metrics.precision_score(y, gda_pred)        # precision tp / (tp + fp)\n",
    "    recall = metrics.recall_score(y, gda_pred)              # recall: tp / (tp + fn)\n",
    "    f1 = metrics.f1_score(y, gda_pred)                      # f1: 2 tp / (2 tp + fp + fn)\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2 precision: 0.542500, recall: 0.542500, f1 score: 0.542500, accuracy: 0.542500\n",
      "K=4 precision: 0.552500, recall: 0.552500, f1 score: 0.552500, accuracy: 0.552500\n",
      "K=6 precision: 0.570000, recall: 0.570000, f1 score: 0.570000, accuracy: 0.570000\n",
      "K=8 precision: 0.553750, recall: 0.553750, f1 score: 0.553750, accuracy: 0.553750\n",
      "K=10 precision: 0.535000, recall: 0.535000, f1 score: 0.535000, accuracy: 0.535000\n",
      "K=12 precision: 0.570000, recall: 0.570000, f1 score: 0.570000, accuracy: 0.570000\n",
      "K=14 precision: 0.565000, recall: 0.565000, f1 score: 0.565000, accuracy: 0.565000\n",
      "K=16 precision: 0.568750, recall: 0.568750, f1 score: 0.568750, accuracy: 0.568750\n",
      "K=18 precision: 0.566250, recall: 0.566250, f1 score: 0.566250, accuracy: 0.566250\n",
      "K=20 precision: 0.573750, recall: 0.573750, f1 score: 0.573750, accuracy: 0.573750\n"
     ]
    }
   ],
   "source": [
    "for k in range (2, 21,2):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    knn_pred = knn_model.predict(x_test)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_test)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=15 precision: 0.562500, recall: 0.562500, f1 score: 0.562500, accuracy: 0.562500\n",
      "K=20 precision: 0.573750, recall: 0.573750, f1 score: 0.573750, accuracy: 0.573750\n",
      "K=25 precision: 0.557500, recall: 0.557500, f1 score: 0.557500, accuracy: 0.557500\n",
      "K=30 precision: 0.556250, recall: 0.556250, f1 score: 0.556250, accuracy: 0.556250\n",
      "K=35 precision: 0.540000, recall: 0.540000, f1 score: 0.540000, accuracy: 0.540000\n",
      "K=40 precision: 0.537500, recall: 0.537500, f1 score: 0.537500, accuracy: 0.537500\n",
      "K=45 precision: 0.542500, recall: 0.542500, f1 score: 0.542500, accuracy: 0.542500\n",
      "K=50 precision: 0.540000, recall: 0.540000, f1 score: 0.540000, accuracy: 0.540000\n"
     ]
    }
   ],
   "source": [
    "for k in range (15, 51, 5):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    knn_pred = knn_model.predict(x_test)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_test)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2 precision: 0.543590, recall: 0.530000, f1 score: 0.536709, accuracy: 0.542500\n",
      "K=4 precision: 0.554974, recall: 0.530000, f1 score: 0.542199, accuracy: 0.552500\n",
      "K=6 precision: 0.572539, recall: 0.552500, f1 score: 0.562341, accuracy: 0.570000\n",
      "K=8 precision: 0.558266, recall: 0.515000, f1 score: 0.535761, accuracy: 0.553750\n",
      "K=10 precision: 0.538043, recall: 0.495000, f1 score: 0.515625, accuracy: 0.535000\n",
      "K=12 precision: 0.576923, recall: 0.525000, f1 score: 0.549738, accuracy: 0.570000\n",
      "K=14 precision: 0.573446, recall: 0.507500, f1 score: 0.538462, accuracy: 0.565000\n",
      "K=16 precision: 0.577031, recall: 0.515000, f1 score: 0.544254, accuracy: 0.568750\n",
      "K=18 precision: 0.574648, recall: 0.510000, f1 score: 0.540397, accuracy: 0.566250\n",
      "K=20 precision: 0.583569, recall: 0.515000, f1 score: 0.547145, accuracy: 0.573750\n"
     ]
    }
   ],
   "source": [
    "#lets check the performance with the validation set too!\n",
    "# start with K=2 to 20\n",
    "for k in range (2, 21,2):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    knn_pred = knn_model.predict(x_valid)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_valid)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=25 precision: 0.564246, recall: 0.505000, f1 score: 0.532982, accuracy: 0.557500\n",
      "K=30 precision: 0.561983, recall: 0.510000, f1 score: 0.534731, accuracy: 0.556250\n",
      "K=35 precision: 0.544444, recall: 0.490000, f1 score: 0.515789, accuracy: 0.540000\n",
      "K=40 precision: 0.542614, recall: 0.477500, f1 score: 0.507979, accuracy: 0.537500\n",
      "K=45 precision: 0.548023, recall: 0.485000, f1 score: 0.514589, accuracy: 0.542500\n",
      "K=50 precision: 0.546784, recall: 0.467500, f1 score: 0.504043, accuracy: 0.540000\n"
     ]
    }
   ],
   "source": [
    "# Lets repeat for K from 25 to 50 as well!\n",
    "for k in range (25, 51, 5):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    knn_pred = knn_model.predict(x_valid)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred,y_valid)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4).\n",
    "\n",
    "4. Now instead of having a single multivariate Gaussian distribution per class, each class\n",
    "is going to be generated by a mixture of 3 Gaussians. For each class, weâ€™ll define\n",
    "3 Gaussians, with the first Gaussian of the first class sharing the covariance matrix\n",
    "with the first Gaussian of the second class and so on. For both the classes, fix the\n",
    "mixture probability as (0.1,0.42,0.48) i.e. the sample has arisen from first Gaussian with\n",
    "probability 0.1, second with probability 0.42 and so on. Mean for three Gaussians in the\n",
    "positive class are given as DS2-c1-m1, DS2-c1-m2, DS2-c1-m3. Mean for three Gaussians\n",
    "in the negative class are gives as DS2-c2-m1, DS2-c2-m2, DS2-c2-m3. Corresponding 3\n",
    "covariance matrices are given as DS2-cov-1, DS2-cov-2 and DS2-cov-3. Now sample\n",
    "from this distribution and generate the dataset similar to question 1. Call this dataset\n",
    "as DS2, and submit it with your code. Follow the instructions from Assignment 1 for\n",
    "data submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 1\n",
    "DS2_c1_m1 = np.genfromtxt(path+'DS2_c1_m1.txt', delimiter=',')[:-1]\n",
    "DS2_c1_m2 = np.genfromtxt(path+'DS2_c1_m2.txt', delimiter=',')[:-1]\n",
    "DS2_c1_m3 = np.genfromtxt(path+'DS2_c1_m3.txt', delimiter=',')[:-1]\n",
    "# class 2\n",
    "DS2_c2_m1 = np.genfromtxt(path+'DS2_c2_m1.txt', delimiter=',')[:-1]\n",
    "DS2_c2_m2 = np.genfromtxt(path+'DS2_c2_m2.txt', delimiter=',')[:-1]\n",
    "DS2_c2_m3 = np.genfromtxt(path+'DS2_c2_m3.txt', delimiter=',')[:-1]\n",
    "# class 3\n",
    "DS2_Cov1 = np.genfromtxt(path+'DS2_Cov1.txt', delimiter=',')[:,:-1]\n",
    "DS2_Cov2 = np.genfromtxt(path+'DS2_Cov2.txt', delimiter=',')[:,:-1]\n",
    "DS2_Cov3 = np.genfromtxt(path+'DS2_Cov3.txt', delimiter=',')[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_choice(list_of_candidates, number_of_items_to_pick, probability_distribution): \n",
    "    return choice(list_of_candidates, number_of_items_to_pick, p=probability_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_random_choice([-1,0,1], 2000, [0.1,0.42,0.48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_c1 = np.count_nonzero(data == -1)\n",
    "num_c2 = np.count_nonzero(data == 0)\n",
    "num_c3 = np.count_nonzero(data == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_positive = np.random.multivariate_normal(DS2_c1_m1, DS2_Cov1, num_c1)\n",
    "c2_positive = np.random.multivariate_normal(DS2_c1_m2, DS2_Cov2, num_c2)\n",
    "c3_positive = np.random.multivariate_normal(DS2_c1_m3, DS2_Cov3, num_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_negative = np.random.multivariate_normal(DS2_c2_m1, DS2_Cov1, num_c1)\n",
    "c2_negative = np.random.multivariate_normal(DS2_c2_m2, DS2_Cov2, num_c2)\n",
    "c3_negative = np.random.multivariate_normal(DS2_c2_m3, DS2_Cov3, num_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_target_value(class_array, target_array):\n",
    "    return np.append(class_array,target_array.reshape(-1,1), axis=1)\n",
    "def append_more_rows(class_array_1, class_array_2):\n",
    "    return np.append(class_array_1,class_array_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' append the target values to the end of the array,\n",
    "    using the append_target_value function defined in the upper scope'''\n",
    "class_c1_positive = append_target_value(c1_positive,np.full(num_c1, -1))\n",
    "class_c2_positive = append_target_value(c2_positive,np.full(num_c2, 0))\n",
    "class_c3_positive = append_target_value(c3_positive,np.full(num_c3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' repeat the append process for the negative class!'''\n",
    "class_c1_negative = append_target_value(c1_negative,np.full(num_c1, -1))\n",
    "class_c2_negative = append_target_value(c2_negative,np.full(num_c2, 0))\n",
    "class_c3_negative = append_target_value(c3_negative,np.full(num_c3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' now we can combine all the positive classes together and negative together'''\n",
    "class_positive = append_more_rows(class_c1_positive,class_c2_positive)\n",
    "class_positive = append_more_rows(class_positive,class_c3_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Repeat for the negative classes'''\n",
    "class_negative = append_more_rows(class_c1_negative,class_c2_negative)\n",
    "class_negative = append_more_rows(class_negative,class_c3_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' now we can split the datasets into train, test and validation in as for question 1'''\n",
    "class_positive_train, class_positive_test = train_test_split(class_positive, test_size=0.2, random_state=42)\n",
    "class_positive_train, class_positive_validate = train_test_split(class_positive_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''repeat the split steps for negative class'''\n",
    "class_negative_train, class_negative_test = train_test_split(class_negative, test_size=0.2, random_state=42)\n",
    "class_negative_train, class_negative_validate = train_test_split(class_negative_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' lets combine the dataset now!'''\n",
    "train_set = append_more_rows(class_positive_train,class_negative_train)\n",
    "test_set = append_more_rows(class_positive_test,class_negative_test)\n",
    "validate_set = append_more_rows(class_positive_validate,class_negative_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 21) (800, 21) (800, 21)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, test_set.shape, validate_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Great every thing looks fine! lets save these dataset then as DS2'''\n",
    "np.savetxt(path_output+\"DS2_train.csv\", train_set, delimiter=\",\")\n",
    "np.savetxt(path_output+\"DS2_test.csv\", test_set, delimiter=\",\")\n",
    "np.savetxt(path_output+\"DS2_validate.csv\", validate_set, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "5. Now perform the experiments in questions 2 and 3 again, but now using DS2. 1. Estimate the parameters of the GDA model using the maximum likelihood approach.\n",
    "\n",
    "    (a) For DS1, report the best fit accuracy, precision, recall and F-measure achieved by the classifier.\n",
    "\n",
    "    (b) Report the coefficients learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = train_set[0:,0:20]\n",
    "y_train2 = train_set[0:,20:]\n",
    "\n",
    "x_test2 = test_set[0:,0:20]\n",
    "y_test2 = test_set[0:,20:]\n",
    "\n",
    "x_valid2 = validate_set[0:,0:20]\n",
    "y_valid2 = validate_set[0:,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_metrics(gda_pred, y):\n",
    "    #print(gda_pred)\n",
    "    accuracy = metrics.accuracy_score(y, gda_pred)          # accuracy: (tp + tn) / (p + n)\n",
    "    precision = metrics.precision_score(y, gda_pred, average='macro')        # precision tp / (tp + fp)\n",
    "    recall = metrics.recall_score(y, gda_pred, average='macro')              # recall: tp / (tp + fn)\n",
    "    f1 = metrics.f1_score(y, gda_pred, average='macro')                      # f1: 2 tp / (2 tp + fp + fn)\n",
    "    #print(metrics.classification_report(y, gda_pred))\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDA:\n",
    "    def __init__(self,train_data,train_label):\n",
    "        self.labels, self.class_priors = np.unique(train_label, return_counts=True)\n",
    "        self.class_priors = self.class_priors / train_label.shape[0]\n",
    "        \n",
    "        self.Train_Data = train_data\n",
    "        self.Train_Label = train_label\n",
    "        \n",
    "        print(self.labels)\n",
    "        \n",
    "        self.dict_data = {}\n",
    "        self.dict_data_count = {}\n",
    "        for (data,label) in zip(self.Train_Data,self.Train_Label):\n",
    " \n",
    "            if label[0] in self.dict_data.keys():\n",
    "                temp = self.dict_data.get(label[0])\n",
    "                temp_count = self.dict_data_count.get(label[0])\n",
    "                temp_count += 1\n",
    "                temp.append(list(data))\n",
    "                self.dict_data[label[0]] = temp\n",
    "                self.dict_data_count[label[0]] = temp_count\n",
    "            else:\n",
    "                self.dict_data[label[0]] = [list(data)]\n",
    "                self.dict_data_count[label[0]] = 1\n",
    "            \n",
    "                    \n",
    "        # Binomial probability goas here:\n",
    "        row,col = np.shape(train_data)\n",
    "        self.binomial_dict = {}\n",
    "        for key, val in self.dict_data_count.items():\n",
    "            self.binomial_dict[key] = val*1.0/row\n",
    "        \n",
    "        dict_data_array = {}\n",
    "        data_sum_dict = {}\n",
    "        for k, v in self.dict_data.items():\n",
    "            dict_data_array[k] = np.array(v)\n",
    "            data_sum_dict[k]= np.sum(np.array(v),0)\n",
    "        \n",
    "        self.mu_data = {}\n",
    "        for k, v in data_sum_dict.items():\n",
    "            self.mu_data[k] = v*1.0/self.dict_data_count[k]\n",
    "            \n",
    "        dict_data_array2 = {}    \n",
    "        for k, v in dict_data_array.items():\n",
    "            dict_data_array2[k] = v-self.mu_data[k]\n",
    "        \n",
    "        self.sigma = []\n",
    "        \n",
    "        for k,v in dict_data_array2.items():\n",
    "            for deta in v:\n",
    "                deta = deta.reshape(1,col)\n",
    "                ans = deta.T.dot(deta)\n",
    "                self.sigma.append(ans)\n",
    "\n",
    "        self.sigma = np.array(self.sigma)\n",
    "        #print(np.shape(self.sigma))\n",
    "        self.sigma = np.sum(self.sigma,0)\n",
    "        self.sigma = self.sigma/row\n",
    "        \n",
    "        \n",
    "        for k, v in self.mu_data.items():\n",
    "            self.mu_data[k] = v.reshape(1,col)\n",
    "            print(\"Mu_{}: {}\".format(k,v.reshape(1,col)))\n",
    "        print(self.sigma)\n",
    "\n",
    "    def Gaussian(self, x, mean, cov):\n",
    "        \n",
    "        dim = np.shape(cov)[0]\n",
    "        # Cov measures of the determinant is zero\n",
    "        covdet = np.linalg.det(cov + np.eye(dim) * 0.001)\n",
    "        covinv = np.linalg.inv(cov + np.eye(dim) * 0.001)\n",
    "        xdiff = (x - mean).reshape((1, dim))\n",
    "        # Probability Density\n",
    "        p_density = 1.0 / (np.power(np.power(2 * np.pi, dim) * np.abs(covdet), 0.5)) * \\\n",
    "               np.exp(-0.5 * xdiff.dot(covinv).dot(xdiff.T))[0][0]\n",
    "        return p_density\n",
    "\n",
    "    def predict(self,test_data):\n",
    "        predict_label = []\n",
    "        for data in test_data:\n",
    "            max_label = 0\n",
    "            max_likehood = 0\n",
    "            for lab in self.labels:\n",
    "                likelihood = self.Gaussian(data,self.mu_data[lab],self.sigma)\n",
    "                if likelihood >= max_likehood:\n",
    "                    max_likehood = likelihood\n",
    "                    max_label = lab\n",
    "            predict_label.append(max_label)\n",
    "        return predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  1.]\n",
      "Mu_0.0: [[1.29724275 1.25102015 1.25004288 1.28276062 1.2989058  1.31526389\n",
      "  1.25354354 1.23550585 1.26595639 1.3037435  1.23173239 1.31843288\n",
      "  1.36190463 1.28937024 1.29656502 1.34739472 1.37227629 1.29930885\n",
      "  1.2857059  1.34835781]]\n",
      "Mu_1.0: [[0.92480382 0.91899941 1.04501533 0.96098354 1.00304952 0.97531307\n",
      "  0.95780066 0.95276701 0.96189318 0.93158991 0.98127981 1.04586067\n",
      "  0.95713262 0.98932708 1.02272357 0.97261192 0.98520985 0.98567112\n",
      "  0.97661387 0.96837571]]\n",
      "Mu_-1.0: [[1.39698335 1.36873928 1.45029711 1.41682151 1.45625061 1.32099039\n",
      "  1.41018726 1.42241944 1.45919498 1.35199226 1.37948593 1.32646174\n",
      "  1.33457397 1.37718355 1.38782479 1.29662418 1.48695119 1.32193448\n",
      "  1.42819359 1.45026341]]\n",
      "[[8.00726296 5.60067864 5.02631111 5.25434576 4.5973586  5.93259356\n",
      "  6.07656546 5.81946632 4.91154092 5.60379888 5.61471706 5.08515782\n",
      "  5.21811786 6.44090769 5.43450398 5.84128789 5.61719372 5.51110253\n",
      "  5.72483433 6.04339909]\n",
      " [5.60067864 7.36789331 5.16497191 5.34621408 5.2107865  6.10033017\n",
      "  6.60786129 5.55069018 4.6878163  5.23267807 4.97850515 5.07408672\n",
      "  5.00757329 6.18936123 5.59418754 5.97860587 5.38762301 5.12748787\n",
      "  6.21297599 5.80947913]\n",
      " [5.02631111 5.16497191 7.21497558 5.47731492 5.03837987 5.03702193\n",
      "  6.30696977 4.84109332 4.81914109 5.16964042 5.06607046 5.17244915\n",
      "  5.37780626 6.33861065 5.4309185  5.13735847 5.68942967 4.54243555\n",
      "  6.07114068 6.03819222]\n",
      " [5.25434576 5.34621408 5.47731492 6.75562042 4.38795799 5.62077912\n",
      "  6.39720386 5.5372126  4.88425802 5.65241944 5.09087441 4.97686715\n",
      "  5.1197695  5.65540727 5.29138147 5.42124972 5.35432742 5.21733159\n",
      "  6.01194649 5.80006305]\n",
      " [4.5973586  5.2107865  5.03837987 4.38795799 5.81635991 4.85012795\n",
      "  5.26274422 4.69438282 3.83742955 4.2644369  3.95061736 4.18695371\n",
      "  4.45858995 4.99142729 5.2004315  5.09719238 4.50631614 4.68646213\n",
      "  5.3689178  5.07692829]\n",
      " [5.93259356 6.10033017 5.03702193 5.62077912 4.85012795 8.02942843\n",
      "  6.76076626 5.39133902 5.64548572 5.70995589 4.87182322 4.92962274\n",
      "  5.57201274 6.55577997 5.62715513 5.99217152 5.72893572 5.49608515\n",
      "  6.63525083 6.24028403]\n",
      " [6.07656546 6.60786129 6.30696977 6.39720386 5.26274422 6.76076626\n",
      "  8.56885541 6.14388516 5.88041025 6.3454096  6.00385044 5.84835986\n",
      "  5.76820925 7.08934452 5.99170912 6.32760724 6.09999121 5.72065845\n",
      "  7.30633144 6.54736602]\n",
      " [5.81946632 5.55069018 4.84109332 5.5372126  4.69438282 5.39133902\n",
      "  6.14388516 6.70207889 4.76563334 5.23941379 4.72783878 4.85635986\n",
      "  4.44073211 5.65416475 5.28637014 5.45588207 5.00705727 5.76928253\n",
      "  5.65232016 5.54749029]\n",
      " [4.91154092 4.6878163  4.81914109 4.88425802 3.83742955 5.64548572\n",
      "  5.88041025 4.76563334 6.0708046  4.78320036 4.37924829 4.35183072\n",
      "  4.553189   5.25403347 4.77978454 4.5224158  4.87022421 4.59207058\n",
      "  4.98757648 5.00890144]\n",
      " [5.60379888 5.23267807 5.16964042 5.65241944 4.2644369  5.70995589\n",
      "  6.3454096  5.23941379 4.78320036 7.03370437 4.90306995 4.72895538\n",
      "  5.14069791 5.90839791 5.18973104 5.259169   5.21990815 4.66275763\n",
      "  6.33781948 5.51888761]\n",
      " [5.61471706 4.97850515 5.06607046 5.09087441 3.95061736 4.87182322\n",
      "  6.00385044 4.72783878 4.37924829 4.90306995 6.25865646 5.15948624\n",
      "  4.74707533 5.37995315 5.1066934  4.75409167 4.98956472 4.58316764\n",
      "  5.75152189 5.47342321]\n",
      " [5.08515782 5.07408672 5.17244915 4.97686715 4.18695371 4.92962274\n",
      "  5.84835986 4.85635986 4.35183072 4.72895538 5.15948624 6.46064867\n",
      "  4.58124875 5.45353896 5.36775766 5.00797037 5.21950325 4.85688421\n",
      "  5.73634042 5.26636536]\n",
      " [5.21811786 5.00757329 5.37780626 5.1197695  4.45858995 5.57201274\n",
      "  5.76820925 4.44073211 4.553189   5.14069791 4.74707533 4.58124875\n",
      "  6.38314389 5.71614199 5.55634906 5.37481657 5.39344094 4.65593095\n",
      "  5.83056917 5.55105715]\n",
      " [6.44090769 6.18936123 6.33861065 5.65540727 4.99142729 6.55577997\n",
      "  7.08934452 5.65416475 5.25403347 5.90839791 5.37995315 5.45353896\n",
      "  5.71614199 8.34220437 5.94602492 5.86965883 6.35753022 4.76313863\n",
      "  6.43123321 6.50790477]\n",
      " [5.43450398 5.59418754 5.4309185  5.29138147 5.2004315  5.62715513\n",
      "  5.99170912 5.28637014 4.77978454 5.18973104 5.1066934  5.36775766\n",
      "  5.55634906 5.94602492 7.15659974 5.37459072 5.51558084 5.28047777\n",
      "  5.90467308 6.15195401]\n",
      " [5.84128789 5.97860587 5.13735847 5.42124972 5.09719238 5.99217152\n",
      "  6.32760724 5.45588207 4.5224158  5.259169   4.75409167 5.00797037\n",
      "  5.37481657 5.86965883 5.37459072 6.76827448 5.37908511 5.64389814\n",
      "  6.23425996 5.81630842]\n",
      " [5.61719372 5.38762301 5.68942967 5.35432742 4.50631614 5.72893572\n",
      "  6.09999121 5.00705727 4.87022421 5.21990815 4.98956472 5.21950325\n",
      "  5.39344094 6.35753022 5.51558084 5.37908511 6.93509073 4.65039004\n",
      "  5.87532444 6.32855549]\n",
      " [5.51110253 5.12748787 4.54243555 5.21733159 4.68646213 5.49608515\n",
      "  5.72065845 5.76928253 4.59207058 4.66275763 4.58316764 4.85688421\n",
      "  4.65593095 4.76313863 5.28047777 5.64389814 4.65039004 6.85059869\n",
      "  5.57796909 5.41872393]\n",
      " [5.72483433 6.21297599 6.07114068 6.01194649 5.3689178  6.63525083\n",
      "  7.30633144 5.65232016 4.98757648 6.33781948 5.75152189 5.73634042\n",
      "  5.83056917 6.43123321 5.90467308 6.23425996 5.87532444 5.57796909\n",
      "  8.46345429 6.55968962]\n",
      " [6.04339909 5.80947913 6.03819222 5.80006305 5.07692829 6.24028403\n",
      "  6.54736602 5.54749029 5.00890144 5.51888761 5.47342321 5.26636536\n",
      "  5.55105715 6.50790477 6.15195401 5.81630842 6.32855549 5.41872393\n",
      "  6.55968962 8.07449314]]\n"
     ]
    }
   ],
   "source": [
    "gda2 = GDA(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = gda2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, accuracy = get_scores_metrics(pred2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.348750\n",
      "Precision: 0.357836\n",
      "Recall: 0.339353\n",
      "F1 score: 0.319012\n"
     ]
    }
   ],
   "source": [
    "#print the results\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2 precision: 0.765114, recall: 0.732873, f1 score: 0.746064, accuracy: 0.808750\n",
      "K=4 precision: 0.822172, recall: 0.728152, f1 score: 0.754473, accuracy: 0.833750\n",
      "K=6 precision: 0.846831, recall: 0.740105, f1 score: 0.769710, accuracy: 0.841250\n",
      "K=8 precision: 0.859159, recall: 0.694358, f1 score: 0.721160, accuracy: 0.828750\n",
      "K=10 precision: 0.860319, recall: 0.689397, f1 score: 0.712655, accuracy: 0.835000\n",
      "K=12 precision: 0.876920, recall: 0.704402, f1 score: 0.733356, accuracy: 0.838750\n",
      "K=14 precision: 0.875071, recall: 0.686617, f1 score: 0.707264, accuracy: 0.838750\n",
      "K=16 precision: 0.871801, recall: 0.676856, f1 score: 0.692126, accuracy: 0.837500\n",
      "K=18 precision: 0.869734, recall: 0.674576, f1 score: 0.690244, accuracy: 0.835000\n",
      "K=20 precision: 0.886367, recall: 0.657015, f1 score: 0.661999, accuracy: 0.831250\n"
     ]
    }
   ],
   "source": [
    "for k in range (2, 21,2):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train2,y_train2)\n",
    "    knn_pred = knn_model.predict(x_test2)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_test2)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=25 precision: 0.881400, recall: 0.648299, f1 score: 0.651022, accuracy: 0.823750\n",
      "K=30 precision: 0.878603, recall: 0.628865, f1 score: 0.616465, accuracy: 0.817500\n",
      "K=35 precision: 0.875967, recall: 0.616688, f1 score: 0.593820, accuracy: 0.813750\n",
      "K=40 precision: 0.872188, recall: 0.612212, f1 score: 0.589453, accuracy: 0.807500\n",
      "K=45 precision: 0.869721, recall: 0.602404, f1 score: 0.571807, accuracy: 0.802500\n",
      "K=50 precision: 0.869283, recall: 0.601075, f1 score: 0.570195, accuracy: 0.800000\n"
     ]
    }
   ],
   "source": [
    "for k in range (25, 51,5):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train2,y_train2)\n",
    "    knn_pred = knn_model.predict(x_test2)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_test2)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2 precision: 0.784622, recall: 0.745737, f1 score: 0.761230, accuracy: 0.831250\n",
      "K=4 precision: 0.816232, recall: 0.733402, f1 score: 0.758021, accuracy: 0.848750\n",
      "K=6 precision: 0.873950, recall: 0.743451, f1 score: 0.775561, accuracy: 0.866250\n",
      "K=8 precision: 0.869872, recall: 0.717134, f1 score: 0.746390, accuracy: 0.856250\n",
      "K=10 precision: 0.870350, recall: 0.696943, f1 score: 0.721114, accuracy: 0.850000\n",
      "K=12 precision: 0.877127, recall: 0.704381, f1 score: 0.728226, accuracy: 0.860000\n",
      "K=14 precision: 0.884943, recall: 0.691222, f1 score: 0.711258, accuracy: 0.855000\n",
      "K=16 precision: 0.871573, recall: 0.667044, f1 score: 0.677065, accuracy: 0.843750\n",
      "K=18 precision: 0.874869, recall: 0.671870, f1 score: 0.684180, accuracy: 0.846250\n",
      "K=20 precision: 0.873480, recall: 0.666361, f1 score: 0.674148, accuracy: 0.847500\n"
     ]
    }
   ],
   "source": [
    "for k in range (2, 21,2):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train2,y_train2)\n",
    "    knn_pred = knn_model.predict(x_valid2)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_valid2)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=25 precision: 0.886115, recall: 0.634610, f1 score: 0.629459, accuracy: 0.826250\n",
      "K=30 precision: 0.887646, recall: 0.633569, f1 score: 0.624977, accuracy: 0.828750\n",
      "K=35 precision: 0.885169, recall: 0.627510, f1 score: 0.615490, accuracy: 0.825000\n",
      "K=40 precision: 0.877862, recall: 0.609737, f1 score: 0.586559, accuracy: 0.813750\n",
      "K=45 precision: 0.877430, recall: 0.609871, f1 score: 0.586605, accuracy: 0.813750\n",
      "K=50 precision: 0.875564, recall: 0.602782, f1 score: 0.575803, accuracy: 0.808750\n"
     ]
    }
   ],
   "source": [
    "for k in range (25, 51,5):\n",
    "    knn_model = KNN(K=k)\n",
    "    knn_model.fit(x_train2,y_train2)\n",
    "    knn_pred = knn_model.predict(x_valid2)# NOTE: predict step in KNN is much slower than the train step\n",
    "    precision, recall, f1, accuracy = get_scores_metrics(knn_pred, y_valid2)\n",
    "    # Print Performance results for each K value\n",
    "    print(\"K=%d precision: %f, recall: %f, f1 score: %f, accuracy: %f\"%(k,precision,recall,f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
